---
title: "Testing merging data from flumes and rainfall"
format: html
editor: visual
---

## Introduction

This notebook demonstrates the different functions that have been developed to analyse and check the field data from La Corona, based on the original work from Prof Chip Cheshier and Prof Francois Birgand at North Carolina State University.

Scripts and functions have been developed as part of FPTA 358 funded by INIA Uy.

This document specifically focuses on the merging of different files originating from the rainfall and flume raw data. This will allow providing 6 minute, daily and monthly summaries.

## Packages

To be able to run this notebook, the following R packages should be available

```{r message = FALSE}
library(tidyverse)  
library(plotly) 
```

## Loading the developed functions

The functions are stored in the scripts folder, the same folder as the code version of this file (the \*.qmd file).

```{r loadfunctions}
source("Functions_merge.R") 
```

## Order of merging files

According to page 23 (Flumes data) in the "Field data analysis, La Corona NCSU" document, the following order should be used for adding files:

-   ISCO sampler (Nivel) V1 or V2 file with csv ending (frequency of download is lower as there is more storage)

-   V1 or V2 elevation (Stevens file with csv.csv ending)

-   S1 or S2 elevation (HOBO20)

-   E1/E2 elevation (this is the emergency spillway) HOBO20

## Testing the functions

We can now start testing the functions.

```{r}
Data_dir = "../All_Raw_Data/Test_T4T52023_folder/T042223"
```

Read in two processed files (rainfall and flume data)

First list the names of the processed files

```{r}
rain_files <- list.files(paste0(Data_dir,"/rain/processed"))
flume_files <- list.files(paste0(Data_dir,"/flumes/processed"))
```

We have the following processed rain files

```{r}
rain_files
```

We have the following processed flume files

```{r}
flume_files
```

Now read in two of the files (**change the file names manually**):

-   rainfall

-   ISCO nivel (a .csv file)

But other files are possible too

Note that here we are using `read_flume_output2()` which is slightly different to `read_flume_output()` in `Functions_Flumes.R`

The file for ISCO nivel is only downloaded at some dates, so we need to check if this file exists, and otherwise create a "dummy" dataframe.

```{r}
rain_file = "OTIP_r7042223.csv"
ISCO_nivel = "V1042223_processed.csv"

rain <- read_otip_file(name = rain_file, 
                       path_to_file = paste0(Data_dir,"/rain/processed"))

if(file.exists(paste0(Data_dir,"/Flumes/processed/",ISCO_nivel))) {
  ISCOnivel <- read_flume_output2(name = ISCO_nivel,
                                path_to_file = paste0(Data_dir,
                                                  "/Flumes/processed"))
  
} else {
  message("ISCO nivel file does not exist: create a dummy df")
  #create a dummy file
  ISCOnivel <- tribble(
    ~`Date and Time`, ~`Water Level, meters`,
    rain$`Date and Time`[nrow(rain)], NA
  )
  }


```

## Merging and summarising

Test summarising the files by 6 min and day before merging. This is to align the timesteps between the different loggers. As `"6 min"` is the default, there is no need for a timestep argument.

Events are summed across summary times, while flume data would be taking the mean value of velocity, height and flow.

```{r summary-test}

test_summary_rain <- sum_fun(rain)

test_summary_flume <- sum_fun(ISCOnivel)

```

Show the results

```{r}
test_summary_flume
```

We will now merge these two files.

In this case **the rainfall file should be df1**, as this has the most dense observations. The function uses full_join to make sure also keep all the observations in df2 (even if there is no equivalent time in df1)

```{r mergetest}
merged_df <- merge_data(test_summary_rain,test_summary_flume)

```

Show the merged data

```{r}
head(merged_df)
```

## Summarising across days and months

We can now also test the summaries across days and months. In this case the timestep argument needs to be defined as `"day"` or `"month"`.

```{r summary-long}

day_summary_rain <- sum_fun(rain, timestep = "day")

day_summary_flume <- sum_fun(ISCOnivel, timestep = "day")

month_summary_rain <- sum_fun(rain, timestep = "month")

month_summary_flume <- sum_fun(ISCOnivel, timestep = "month")
```

These can also be merged

```{r merge-long}
day_merged_df <- merge_data(day_summary_rain,day_summary_flume)
month_merged_df <- merge_data(month_summary_rain,
                              month_summary_flume)

```

## Graphs

With the merged data sets we can now plot the variables against each other.

Starting with the 6 min data

```{r plotting-6min}
p <- merged_df %>%
  #pivot_longer(2:3,values_to = "value", names_to="variable") %>%
  ggplot(aes(`Date and Time`, Event*0.2)) + 
  geom_point(colour = "blue") +
    #geom_bar(stat = "identity", fill = "blue") +
  geom_line(aes(`Date and Time`, `Water Level, meters`), colour = "red") + theme_bw() + 
  scale_y_continuous(sec.axis =sec_axis( trans=~., name="Water Level in Meters")) 
p
ggplotly(p)


```

```{r plotting-day}
p1 <- day_merged_df %>%
  #pivot_longer(2:3,values_to = "value", names_to="variable") %>%
  ggplot(aes(`Date and Time`, Event)) + geom_bar(stat = "identity", fill = "blue") +
  geom_line(aes(`Date and Time`, `Water Level, meters`*50), colour = "red") + theme_bw() +
  scale_y_continuous(
    # Features of the first axis
    name = "Event",
    # Add a second axis and specify its features
    sec.axis = sec_axis( trans=~./50, name="Water Level in Meters")
  )
p1
ggplotly(p1)
```

```{r plotting-month}
p2 <- month_merged_df %>%
  #pivot_longer(2:3,values_to = "value", names_to="variable") %>%
  ggplot(aes(`Date and Time`, Event*0.2)) + geom_bar(stat = "identity", fill = "blue") +
  geom_line(aes(`Date and Time`, `Water Level, meters`*1000), colour = "red") + theme_bw() +
  scale_y_continuous(
    # Features of the first axis
    name = "Event",
    # Add a second axis and specify its features
    sec.axis = sec_axis( trans=~./1000, name="Water Level in Meters")
  )
#p1
ggplotly(p2)
```

### Adding another file (Hobo Stevens)

The next test is whether we can add a further file to the data. Reading in an isco velocity file

```{r}
file_Stevens = "v1042223csv_processed.csv"

flume <- read_flume_output2(name = file_Stevens,
                          path_to_file = paste0(Data_dir,"/Flumes/processed"))
```

Summarise this data to 6 min data

```{r}
test_summary_stevens <- sum_fun(flume)
test_summary_stevens
```

Now add this to the other two datasets

```{r}
merged_three_df <- merge_data(merged_df,test_summary_stevens, by = "Date and Time")
merged_three_df
```

Manually change the names of the water level columns

**You have to change this depending on the files that you have merged**

```{r}
colnames(merged_three_df)[3:4] <- c("ISCO Water Level, meters", "Stevens, Water Level, meters")
```

Now do the plotting. This might require a bit of scaling to make sure this plots well

```{r plotting3-6min}
p3 <- merged_three_df %>%
  pivot_longer(3:ncol(merged_three_df),values_to = "value", 
               names_to="variable") %>%
  ggplot(aes(`Date and Time`, Event*0.2)) + 
  geom_point(colour = "blue", alpha = 0.5) +
  #geom_bar(stat="identity", fill = "darkblue") + 
  geom_line(aes(`Date and Time`,value, colour =variable)) + 
  theme_bw() + ylab("Rainfall (mm)") + 
  scale_y_continuous(sec.axis = sec_axis(trans=~., name = "water level (m)"))
p3
ggplotly(p3)


```

This indicates that the Stevens offset is wrong, possibly the tape has shifted.

### Add a final file (HOBO20 upstream)

This is an S1 or S2 file

```{r}
flume_hobo20 <- read_flume_output2(name = "S1042223_processed.csv",
                          path_to_file = paste0(Data_dir,"/Flumes/processed"))
```

Again, summarise first to 6min data:

```{r}
test_summary_hobo20 <- sum_fun(flume_hobo20)
test_summary_hobo20
```

Add this to the rest of the data

```{r}
merged_four_df <- merge_data(merged_three_df,test_summary_hobo20, by = "Date and Time")
merged_four_df
```

Manually change the name of the last column

```{r}
merged_four_df <- merged_four_df %>%
  rename("HOBO20 Water Level, meters" = "Water Level, meters")
```

We can again plot this

```{r plotting-four}
p4 <- merged_four_df %>%
  pivot_longer(3:ncol(merged_four_df),values_to = "value", 
               names_to="variable") %>%
  ggplot(aes(`Date and Time`, Event*0.2)) + 
  geom_point(colour = "blue", alpha = 0.5) +
  #geom_bar(stat="identity", fill = "darkblue") + 
  geom_line(aes(`Date and Time`,value, colour =variable)) + 
  theme_bw() + ylab("Rainfall (mm)") + 
  scale_y_continuous(sec.axis = sec_axis(trans=~., name = "water level (m)"))
p4
ggplotly(p4)

```

```{# {r}
# # testing ft
# merged_four_df_test <- merged_four_df %>%
#   mutate(`ISCO Water Level, meters` = 0.3*`ISCO Water Level, meters`)
# p4a <- merged_four_df_test %>%
#   pivot_longer(3:ncol(merged_four_df),values_to = "value", 
#                names_to="variable") %>%
#   ggplot(aes(`Date and Time`, Event*0.2)) + 
#   geom_point(colour = "blue", alpha = 0.5) +
#   #geom_bar(stat="identity", fill = "darkblue") + 
#   geom_line(aes(`Date and Time`,value, colour =variable)) + 
#   theme_bw() + ylab("Rainfall (mm)") + 
#   scale_y_continuous(sec.axis = sec_axis(trans=~., name = "water level (m)"))
# p4a
# ggplotly(p4a)
# 

```

## Write out the data

We can now write out the different data sets to files to be used later.

This will be stored in a folder called "combined".

```{r store-data}

if (!file.exists("../All_Raw_Data/Test_T4T52023_folder/combined")) {
  dir.create("../All_Raw_Data/Test_T4T52023_folder/combined")
}

split_dir <- strsplit(Data_dir,"/")
file_indicator <- split_dir[[1]][length(split_dir[[1]])]

write_csv(merged_four_df, paste0("../All_Raw_Data/Test_T4T52023_folder/combined/Rain_flumes_combinedV1",
                                 file_indicator,".csv"))


```

You can store the other data in the same way if needed.
